"""
Reddit Scraper - Growing communities and trending topics
"""

import asyncio
import logging
import random
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

class RedditScraper:
    """Reddit data scraper for community analysis"""
    
    def __init__(self):
        # Sample subreddit data for realistic metrics
        self.popular_subreddits = {
            'technology': 14500000,
            'personalfinance': 15200000,
            'entrepreneur': 985000,
            'programming': 4800000,
            'fitness': 2100000,
            'investing': 1800000,
            'productivity': 245000,
            'digitalnomad': 985000,
            'cryptocurrency': 5200000,
            'business': 875000,
            'marketing': 256000,
            'webdev': 845000,
            'freelance': 125000,
            'sidehustle': 185000,
            'passive_income': 95000,
            'fire': 1200000,  # Financial Independence Retire Early
            'getmotivated': 17500000,
            'lifeprotips': 22100000,
            'todayilearned': 27800000,
            'explainlikeimfive': 20800000
        }
    
    async def get_growing_topics(self) -> List[str]:
        """Get topics from fast-growing Reddit communities"""
        # Simulate growing topics based on current trends
        growing_topics = [
            "AI automation",
            "remote work productivity",
            "sustainable investing", 
            "digital minimalism",
            "career switching",
            "mental health support",
            "side hustle strategies",
            "crypto DeFi",
            "plant-based nutrition",
            "indie game development",
            "freelance writing",
            "solopreneurship",
            "financial literacy",
            "coding bootcamps",
            "work-life balance"
        ]
        
        random.shuffle(growing_topics)
        return growing_topics[:12]
    
    async def get_niche_metrics(self, niche_name: str) -> Dict[str, Any]:
        """Get Reddit metrics for a specific niche"""
        try:
            logger.debug(f"Getting Reddit metrics for: {niche_name}")
            
            # Find relevant subreddits and estimate metrics
            members = self._estimate_community_size(niche_name)
            activity_score = self._estimate_activity_level(niche_name)
            growth_rate = self._estimate_growth_rate(niche_name)
            engagement = self._estimate_engagement(niche_name)
            
            # Add realistic delay
            await asyncio.sleep(random.uniform(0.1, 0.4))
            
            return {
                'members': members,
                'activity_score': activity_score,
                'growth_rate': growth_rate,
                'engagement_rate': engagement,
                'relevant_subreddits': self._find_relevant_subreddits(niche_name),
                'top_posts_score': random.randint(500, 5000),
                'community_health': self._assess_community_health(members, activity_score)
            }
            
        except Exception as e:
            logger.error(f"Error getting Reddit metrics for '{niche_name}': {e}")
            raise
    
    def _estimate_community_size(self, niche: str) -> int:
        """Estimate total community size across relevant subreddits"""
        niche_lower = niche.lower()
        total_members = 0
        
        # Check for direct matches first
        for subreddit, members in self.popular_subreddits.items():
            if subreddit in niche_lower or any(word in subreddit for word in niche.split()):
                total_members += members
        
        # If no direct matches, estimate based on niche characteristics
        if total_members == 0:
            base_size = 50000
            
            # Popular categories get larger communities
            popular_keywords = [
                'money', 'finance', 'business', 'tech', 'ai', 'crypto',
                'fitness', 'health', 'programming', 'investing'
            ]
            
            multiplier = 1.0
            for keyword in popular_keywords:
                if keyword in niche_lower:
                    multiplier *= random.uniform(2.0, 8.0)
                    break
            
            # Niche topics have smaller but more engaged communities
            if len(niche.split()) > 2:  # More specific = smaller community
                multiplier *= 0.6
            
            total_members = int(base_size * multiplier)
        
        return max(1000, min(20000000, total_members))
    
    def _estimate_activity_level(self, niche: str) -> float:
        """Estimate activity level (0-10 scale)"""
        niche_lower = niche.lower()
        
        # High-activity categories
        high_activity = [
            'crypto', 'trading', 'investing', 'tech', 'programming', 
            'gaming', 'politics', 'news'
        ]
        
        # Medium-activity categories
        medium_activity = [
            'business', 'marketing', 'fitness', 'health', 'education',
            'productivity', 'lifestyle'
        ]
        
        # Check activity level
        if any(keyword in niche_lower for keyword in high_activity):
            return round(random.uniform(7.5, 9.5), 1)
        elif any(keyword in niche_lower for keyword in medium_activity):
            return round(random.uniform(5.0, 7.5), 1)
        else:
            return round(random.uniform(3.0, 6.0), 1)
    
    def _estimate_growth_rate(self, niche: str) -> float:
        """Estimate monthly growth rate"""
        niche_lower = niche.lower()
        
        # Fast-growing categories
        hot_topics = [
            'ai', 'artificial intelligence', 'crypto', 'nft', 'remote work',
            'sustainability', 'mental health', 'side hustle'
        ]
        
        base_growth = 0.05  # 5% monthly base
        
        # Check for hot topics
        for topic in hot_topics:
            if topic in niche_lower:
                base_growth *= random.uniform(2.0, 4.0)
                break
        
        # Mature topics grow slower
        mature_topics = ['fitness', 'cooking', 'music', 'gaming']
        if any(topic in niche_lower for topic in mature_topics):
            base_growth *= random.uniform(0.3, 0.8)
        
        return round(base_growth, 3)
    
    def _estimate_engagement(self, niche: str) -> float:
        """Estimate engagement rate (comments/upvotes per post)"""
        niche_lower = niche.lower()
        
        # High-engagement categories (controversial or passionate topics)
        high_engagement = [
            'investing', 'crypto', 'politics', 'relationship', 'career',
            'entrepreneur', 'finance'
        ]
        
        if any(keyword in niche_lower for keyword in high_engagement):
            return round(random.uniform(0.15, 0.35), 3)  # 15-35% engagement
        else:
            return round(random.uniform(0.05, 0.20), 3)  # 5-20% engagement
    
    def _find_relevant_subreddits(self, niche: str) -> List[Dict[str, Any]]:
        """Find relevant subreddits for a niche"""
        niche_lower = niche.lower()
        relevant = []
        
        # Map niche keywords to subreddits
        keyword_mapping = {
            'ai': ['artificial', 'MachineLearning', 'deeplearning', 'ChatGPT'],
            'crypto': ['cryptocurrency', 'Bitcoin', 'ethereum', 'CryptoCurrency'],
            'business': ['entrepreneur', 'business', 'smallbusiness', 'startups'],
            'money': ['personalfinance', 'investing', 'fire', 'passive_income'],
            'tech': ['technology', 'programming', 'webdev', 'coding'],
            'fitness': ['fitness', 'bodybuilding', 'nutrition', 'loseit'],
            'productivity': ['productivity', 'getmotivated', 'studytips']
        }
        
        for keyword, subreddits in keyword_mapping.items():
            if keyword in niche_lower:
                for sub in subreddits[:3]:  # Top 3 relevant subs
                    members = self.popular_subreddits.get(sub.lower(), random.randint(10000, 500000))
                    relevant.append({
                        'name': sub,
                        'members': members,
                        'relevance_score': random.uniform(0.7, 0.95)
                    })
                break
        
        # If no specific mapping, create generic relevant communities
        if not relevant:
            for i in range(2):
                relevant.append({
                    'name': f"{niche.replace(' ', '').lower()}{i+1}",
                    'members': random.randint(5000, 100000),
                    'relevance_score': random.uniform(0.6, 0.85)
                })
        
        return relevant
    
    def _assess_community_health(self, members: int, activity: float) -> str:
        """Assess overall community health"""
        if members > 1000000 and activity > 7.0:
            return "EXCELLENT"
        elif members > 100000 and activity > 5.0:
            return "GOOD"
        elif members > 10000 and activity > 3.0:
            return "MODERATE"
        else:
            return "POOR"
    
    async def get_trending_posts(self, subreddit: str, timeframe: str = "day") -> List[Dict[str, Any]]:
        """Get trending posts from a subreddit"""
        # Simulate trending posts
        post_titles = [
            "Just launched my side hustle and made $1000 in the first week!",
            "Ultimate guide to getting started with [TOPIC]",
            "Mistake I made that cost me $10,000 - learn from my failure",
            "Finally achieved financial independence at 35 - AMA",
            "Tools and resources that changed my life",
            "Why everyone is wrong about [CONTROVERSIAL TOPIC]"
        ]
        
        posts = []
        for i, title in enumerate(post_titles[:random.randint(3, 6)]):
            posts.append({
                'title': title.replace('[TOPIC]', subreddit).replace('[CONTROVERSIAL TOPIC]', f"{subreddit} strategies"),
                'score': random.randint(500, 15000),
                'comments': random.randint(50, 1500),
                'engagement_rate': random.uniform(0.05, 0.25),
                'created_hours_ago': random.randint(1, 24)
            })
        
        return sorted(posts, key=lambda x: x['score'], reverse=True)
    
    async def analyze_sentiment(self, niche: str) -> Dict[str, Any]:
        """Analyze sentiment around a niche topic"""
        # Simulate sentiment analysis
        positive_keywords = ['success', 'achievement', 'growth', 'profit', 'win']
        negative_keywords = ['scam', 'loss', 'failure', 'difficult', 'expensive']
        
        niche_lower = niche.lower()
        
        # Calculate sentiment based on keywords
        sentiment_score = 0.5  # Neutral baseline
        
        if any(word in niche_lower for word in positive_keywords):
            sentiment_score += random.uniform(0.1, 0.3)
        
        if any(word in niche_lower for word in negative_keywords):
            sentiment_score -= random.uniform(0.1, 0.3)
        
        sentiment_score = max(0.0, min(1.0, sentiment_score))
        
        return {
            'sentiment_score': round(sentiment_score, 3),
            'sentiment_label': 'POSITIVE' if sentiment_score > 0.6 else 'NEGATIVE' if sentiment_score < 0.4 else 'NEUTRAL',
            'confidence': random.uniform(0.7, 0.95)
        }

# Example usage
async def test_reddit_scraper():
    """Test the Reddit scraper"""
    scraper = RedditScraper()
    
    print("ðŸ”´ Testing Reddit Scraper...")
    
    # Test growing topics
    growing = await scraper.get_growing_topics()
    print(f"\nðŸ“ˆ Growing Topics: {growing[:3]}")
    
    # Test niche metrics
    test_niche = "passive income"
    metrics = await scraper.get_niche_metrics(test_niche)
    print(f"\nðŸ“Š Reddit Metrics for '{test_niche}':")
    for key, value in metrics.items():
        print(f"   {key}: {value}")

if __name__ == "__main__":
    asyncio.run(test_reddit_scraper())